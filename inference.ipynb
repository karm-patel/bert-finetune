{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674abcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96eb519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karm/miniconda3/envs/torch310/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9387c32f",
   "metadata": {},
   "source": [
    "### load bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3114b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.SST2.dataloader import BertDataset, BertCustomDataset\n",
    "from models.bert import BERT\n",
    "MAX_SENT_LENGTH = 56\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad723c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-base-uncased'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which = \"base\"\n",
    "bert_model_name = f\"bert-{which}-uncased\"\n",
    "bert_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b90bf2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained(bert_model_name)\n",
    "sst2_model = BERT(n_classes=2, d_model=768, H=50).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c7290b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = f\"ckpts/{bert_model_name}_SST2_3_2e-05_FULL.pt\"\n",
    "sst2_model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977dadf6",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56cb25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "test_dataset= BertDataset(tokenizer, max_length=MAX_SENT_LENGTH, split=\"test\")\n",
    "test_dataloader=DataLoader(dataset=test_dataset,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "015c126d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 0/28 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/karm/miniconda3/envs/torch310/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy :0.9139908256880734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# test dataset\n",
    "model = sst2_model\n",
    "\n",
    "model.eval()\n",
    "loop=tqdm(enumerate(test_dataloader),leave=False,total=len(test_dataloader))\n",
    "total_matches = 0\n",
    "with torch.no_grad():\n",
    "    for batch, dl in loop:\n",
    "        ids, token_type_ids, mask, label = dl['ids'], dl['token_type_ids'], dl['mask'], dl['target']\n",
    "        output=F.softmax(model(ids=ids,mask=mask,token_type_ids=token_type_ids), dim=1)\n",
    "        pred = torch.argmax(output, dim=-1)\n",
    "        matches = torch.sum(pred == label)\n",
    "        total_matches += matches.item()\n",
    "\n",
    "\n",
    "    print(f\"Test Accuracy :{total_matches/len(test_dataset)}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd2edd",
   "metadata": {},
   "source": [
    "### Custom sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7ed7b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_sst2(model, tokenizer, custom_sentences):\n",
    "    custom_dataset = BertCustomDataset(tokenizer, 56, custom_sentences, device=device)\n",
    "    custom_dataloader = DataLoader(custom_dataset, batch_size=len(custom_sentences))\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():    \n",
    "        data = next(iter(custom_dataloader))\n",
    "        ids, token_type_ids, mask = data['ids'], data['token_type_ids'], data['mask']\n",
    "        output=F.softmax(model(ids=ids,mask=mask,token_type_ids=token_type_ids), dim=1)\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(custom_sentences, columns=[\"input\"])\n",
    "        df[\"Prediction\"] = torch.argmax(output, dim=-1).to(cpu_device)\n",
    "        df[\"Prediction\"] = df[\"Prediction\"].apply(lambda x: {0: \"Negative\", 1: \"Positive\"}[x])\n",
    "        df[\"Probability\"] = torch.max(output, dim=-1).values.to(cpu_device)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20c32878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You made 100 run in only 50 balls</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.947929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fantastic! You made only 1 run in 50 balls</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.833501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Despite being a topper you are just passed</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.688427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you have not studied, still you are passed, great!</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.809652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input Prediction  Probability\n",
       "0                   You made 100 run in only 50 balls   Negative     0.947929\n",
       "1          fantastic! You made only 1 run in 50 balls   Positive     0.833501\n",
       "2          Despite being a topper you are just passed   Negative     0.688427\n",
       "3  you have not studied, still you are passed, great!   Positive     0.809652"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_sentences = [\"You made 100 run in only 50 balls\", \n",
    "                    \"fantastic! You made only 1 run in 50 balls\", \n",
    "                    \"Despite being a topper you are just passed\", \n",
    "                    \"you have not studied, still you are passed, great!\"]\n",
    "get_predictions_sst2(sst2_model, tokenizer, custom_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfebc553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch310]",
   "language": "python",
   "name": "conda-env-torch310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
